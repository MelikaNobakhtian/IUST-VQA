{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pickle\nimport json\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport gensim\nimport gensim.downloader as api\nimport torchtext\nimport torch\nfrom torch import nn\nimport math","metadata":{"id":"ZO77AlhMqPZA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = '../input/minivqaiust/'","metadata":{"id":"hynIcIsFqruY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open(path + \"image_features.pickle\", 'rb') as f:\n    img = pickle.load(f)\nwith open(path + \"image_question.json\") as json_file:\n      img_q = json.load(json_file)","metadata":{"id":"AcG5YI-5qxiC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(path + \"train.csv\")\nq_train_idx = list(df['question_id'])\nlabel_train = list(df['label'])\ndf = pd.read_csv(path + \"val.csv\")\nq_val_idx = list(df['question_id'])\nlabel_val = list(df['label'])\ndf = pd.read_csv(path + \"test.csv\")\nq_test_idx = list(df['question_id'])","metadata":{"id":"II_LeQB4q1T7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"questions_train = []\nimage_features_train = []\nall_qs = {}\n\n#change format for better performing\nfor idx, imq in img_q.items():\n  for ques in imq:\n    all_qs[ques[0]] = {'question':ques[1], 'image_id': str(idx)}\nall_qs[131087000]","metadata":{"id":"MTOrSkdgrJxV","outputId":"9a3502a3-ad6a-41bd-dca0-83b48665a054","execution":{"iopub.status.busy":"2021-10-06T20:43:42.219319Z","iopub.execute_input":"2021-10-06T20:43:42.22042Z","iopub.status.idle":"2021-10-06T20:43:42.307086Z","shell.execute_reply.started":"2021-10-06T20:43:42.220317Z","shell.execute_reply":"2021-10-06T20:43:42.305772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for idx in q_train_idx:\n  questions_train.append(all_qs[idx]['question'])\n  image_features_train.append(img[all_qs[idx]['image_id']])","metadata":{"id":"1uOg9bf8rRGa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"questions_val = []\nimage_features_val = []\n\nfor idx in q_val_idx:\n  questions_val.append(all_qs[idx]['question'])\n  image_features_val.append(img[all_qs[idx]['image_id']])","metadata":{"id":"WCyYRf4TrUn_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"questions_test = []\nimage_features_test = []\n\nfor idx in q_test_idx:\n  questions_test.append(all_qs[idx]['question'])\n  image_features_test.append(img[all_qs[idx]['image_id']])","metadata":{"id":"UoYVxO6FrVaj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TextEmbedding(nn.Module):\n    def __init__(self, vocab_size, embed_dim):\n        super().__init__()\n        self.embedding = nn.Embedding(vocab_size, embed_dim)\n\n    def forward(self, q):\n        x = self.embedding(q)\n        return x","metadata":{"id":"ThmTHetqrZA4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pre_model = api.load('word2vec-google-news-300')","metadata":{"id":"H7gTSOZyrkXl","outputId":"5d868054-bf9f-4dd9-f595-6cfc7b2777ba"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = torchtext.data.utils.get_tokenizer('basic_english')","metadata":{"id":"PitvzIQoruDU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vocab = list(pre_model.vocab.keys())\nembed_size = len(pre_model.get_vector('me'))\nweights = torch.from_numpy(pre_model.vectors)","metadata":{"id":"O2rlBOdtr4vj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"word_dict = {}\nfor idx , word in enumerate(vocab):\n  word_dict[word] = idx","metadata":{"id":"6ZvEi5BlUdb7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"process_text = TextEmbedding(\n    vocab_size = len(vocab) + 1, \n    embed_dim = embed_size\n)","metadata":{"id":"36v8xEZMr-CF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def encode(seq):\n  code = []\n  for tok in tokenizer(seq):\n    try:\n      code.append(word_dict[tok])\n    except:\n      code.append(len(vocab))\n  return code","metadata":{"id":"gin3905vsNYf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def padify(b):\n  v = [encode(x) for x in b]\n  l = max(map(len,v))\n  return torch.stack([torch.nn.functional.pad(torch.tensor(t),(0,l-len(t)),mode='constant',value=0) for t in v])","metadata":{"id":"d4mRMPB7sXX5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_question_pad = padify(questions_train)\nval_question_pad = padify(questions_val)","metadata":{"id":"-QymN996scIE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_question_pad = padify(questions_test)","metadata":{"id":"LZyPycn5shRt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with torch.no_grad():\n  question_embedd_train = process_text(train_question_pad)\nwith torch.no_grad():\n  question_embedd_val = process_text(val_question_pad)","metadata":{"id":"dheJb0VoslqV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with torch.no_grad():\n  question_embedd_test = process_text(test_question_pad)","metadata":{"id":"Vd3LgI5tswVg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class LxmertAttention(nn.Module):\n    def __init__(self, hidden_size, num_attention_heads):\n        super().__init__()\n        if hidden_size % num_attention_heads != 0:\n            raise ValueError(\n                f\"The hidden size ({hidden_size}) is not a multiple of the number of attention \"\n                f\"heads ({num_attention_heads})\"\n            )\n        self.num_attention_heads = num_attention_heads\n        self.attention_head_size = int(hidden_size / num_attention_heads)\n        self.head_size = self.num_attention_heads * self.attention_head_size\n\n        ctx_dim = hidden_size\n        self.query = nn.Linear(hidden_size, self.head_size)\n        self.key = nn.Linear(ctx_dim, self.head_size)\n        self.value = nn.Linear(ctx_dim, self.head_size)\n\n    def transpose_for_scores(self, x):\n        new_x_shape = x.size()[:-1] + (\n            self.num_attention_heads,\n            self.attention_head_size,\n        )\n        x = x.view(*new_x_shape)\n        return x.permute(0, 2, 1, 3)\n\n    def forward(self, hidden_states, context):\n        mixed_query_layer = self.query(hidden_states)\n        mixed_key_layer = self.key(context)\n        mixed_value_layer = self.value(context)\n\n        query_layer = self.transpose_for_scores(mixed_query_layer)\n        key_layer = self.transpose_for_scores(mixed_key_layer)\n        value_layer = self.transpose_for_scores(mixed_value_layer)\n\n        # Take the dot product between \"query\" and \"key\" to get the raw attention scores.\n        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n        attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n\n        # Normalize the attention scores to probabilities.\n        attention_probs = nn.Softmax(dim=-1)(attention_scores)\n\n        context_layer = torch.matmul(attention_probs, value_layer)\n        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n        new_context_layer_shape = context_layer.size()[:-2] + (self.head_size,)\n        context_layer = context_layer.view(*new_context_layer_shape)\n\n        outputs = context_layer\n        return outputs","metadata":{"id":"1BJCASTXbJRp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class LxmertCrossAttentionLayer(nn.Module):\n    def __init__(self,hidden_size, num_attention_heads):\n        super().__init__()\n        self.att = LxmertAttention(hidden_size, num_attention_heads)\n        self.linear = nn.Linear(hidden_size, hidden_size)\n        self.relu = nn.ReLU()\n        self.norm1 = nn.LayerNorm(hidden_size, eps=1e-6)\n        self.norm2 = nn.LayerNorm(hidden_size, eps=1e-6)\n        self.linear = nn.Linear(hidden_size, hidden_size)\n\n    def forward(self, input_tensor, ctx_tensor):\n        output = self.att(input_tensor, ctx_tensor)\n        norm1 = self.norm1(input_tensor + output)\n        lin = self.linear(norm1)\n        return lin","metadata":{"id":"CGdvB_Gvf8NO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = torch.utils.data.TensorDataset(question_embedd_train, torch.tensor(image_features_train), torch.tensor(label_train))\ntrain_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)","metadata":{"id":"Lxucunhr-ZNP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_dataset = torch.utils.data.TensorDataset(question_embedd_val, torch.tensor(image_features_val), torch.tensor(label_val))\nval_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=True)","metadata":{"id":"vh6cHCB4-fYO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class VQA3(nn.Module):\n    def __init__(self, features_size, num_attention_heads):\n        super(type(self), self).__init__()\n        #text feature\n        self.lstm = nn.LSTM(300, features_size, num_layers=2, batch_first = True)\n        #cross attention\n        self.cross = LxmertCrossAttentionLayer(features_size, num_attention_heads)\n        #final output\n        self.linear1 = nn.Linear(features_size, 10)\n        self.batchnorm = nn.BatchNorm1d(features_size)\n                \n        \n    def forward(self, text, image):\n        text_f = self.lstm(text)[0]\n        text_f = torch.mean(text_f,1)\n        text_f = torch.reshape(text_f, (text_f.shape[0], 1, text_f.shape[1]))\n        image = torch.reshape(image, (image.shape[0], 1, image.shape[1]))\n        crossatt = self.cross(text_f, image)\n        crossatt = torch.reshape(crossatt,(crossatt.shape[0], crossatt.shape[2]))\n        crossatt = self.batchnorm(crossatt)\n        crossatt = self.linear1(crossatt)\n        logits = nn.functional.softmax(crossatt, dim=1)\n        return logits","metadata":{"id":"A7NjJvu4-6Ia"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"main_model = VQA3(512, 4)","metadata":{"id":"51ZVwTYGkveu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learning_rate = 0.3\nepochs = 30\nloss_fn = nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(main_model.parameters(), lr=learning_rate)\nscheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)","metadata":{"id":"8eytNpHIltCM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_loop(dataloader, model, loss_fn, optimizer):\n    size = len(dataloader.dataset)\n    for batch, (text, image, y) in enumerate(dataloader):        \n        # Compute prediction and loss\n        pred = model(text, image)\n        #print('hello')\n        loss = loss_fn(pred, y)\n        \n        # Backpropagation\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        #print(batch)\n\n        if batch % 2 == 0:\n            loss, current = loss.item(), batch * len(text)\n            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n","metadata":{"id":"4iydVVWkl2E1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test_loop(dataloader, model, loss_fn):\n    size = len(dataloader.dataset)\n    test_loss, correct = 0, 0\n\n    with torch.no_grad():\n        for text, image, y in dataloader:\n            pred = model(text, image)\n            test_loss += loss_fn(pred, y).item()\n            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n            \n    test_loss /= size\n    correct /= size\n    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")","metadata":{"id":"Rbi-3-A0l7-_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for t in range(epochs):\n    print(f\"Epoch {t+1}\\n-------------------------------\")\n    train_loop(train_dataloader, main_model, loss_fn, optimizer)\n    test_loop(val_dataloader, main_model, loss_fn)\n    scheduler.step()\nprint(\"Done!\")","metadata":{"id":"MRRcH-MnmCNb","outputId":"86696ed6-ea7e-445e-9e93-3ed5a7952e1f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = main_model(question_embedd_test, torch.tensor(image_features_test))","metadata":{"id":"thF8ggW223eO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results = [int(out.argmax(0).numpy()) for out in y]\nlabeldict = {}\nlabeldict['question_id'] = q_test_idx\nlabeldict['label'] = []\nfor idx, out in enumerate(results):\n  labeldict['label'].append(int(out))","metadata":{"id":"vVFx7vr03pgb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dfl = pd.DataFrame(labeldict)  ","metadata":{"id":"-oRtPYS85VxN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dfl","metadata":{"id":"q4GJpbkn5eOe","outputId":"d1ebfc72-c681-4376-822c-731ab3dc9462"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dfl.to_csv(path + 'testvqa3_again.csv', index=False)","metadata":{"id":"DvR16wF15oTR"},"execution_count":null,"outputs":[]}]}